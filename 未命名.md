彩票假设的提出，揭示了网络结构和初始化参数与神经网络学习潜力间的关系，原始彩票假设在训练收敛后进行剪枝和权值重置，使其面临着遗忘学习知识且训练成本高的问题。因此我们提出了一种将神经网络结构搜索思想与剪枝算法相结合的策略来缓解这一问题。

这一算法通过迭代的方式，在已有的彩票子网基础上进行网络结构的搜索和扩展。这样可以在不损害性能的情况下继续训练和剪枝过程。以递归的方式来得到一个新的网络结构更深，泛化能力更好，测试性能更好的彩票子网。

由此可以解决：剪枝后子网训练困难或性能下降，原始彩票假设的权值遗忘和在未给定最终网络结构时彩票子网的生成困难。我们将这一策略在MNIST和CIFAR-10数据集上做了验证，在与近年来相关的彩票假设研究相联系后，我们将进一步讨论让网络保持幼态的因素，也就是那些在训练过程中影响神经网络学习潜力或性能提升潜力的决定性因素。

  